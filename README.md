# lucene-sequence-diagram
lucene搜索端uml时序图，lucene源码解析

图比较大，看不清，可以下载【sd-search.svg】后再用浏览器打开

使用starUML画图，可以下载【lucene.mdj】后打开，编辑

# 前提
只考虑最简单的查询，比如只对一个字段，用一个term去查,即TermQuery；然后索引也只有一个segment，简单的情况利于理解。

# 步骤
以下只描述了几个重要步骤，包含了加权，读取索引文件，收集，评分，分页这几个重要步骤。

- 1 加权；图中第【2】步,使用query生成weight；query就是查询参数，weight即对查询参数赋予权重，比如查询title包含"lucene"的文章,则首先对"lucene"这个term赋予权重

- - 1.1 对"lucene"这个term赋予权重,需要先从索引文件中读取"title"这个字段的倒排表信息，即图中第【6】步，真真实实的从文件中读取索引信息

- - 1.2　对"title"这个字段统计基本信息，比如有多少文档包含这个字段，在这些文档中有多少包含"lucene"这个term等等,步骤【9】,【10】完成这些统计

- - 1.3　有了这些统计信息以后，就可以计算"title"字段中，"lucenen"这个term的权重了，步骤【13】计算权重。如果是TF-IDF模型的话，这一步就是计算【IDF值】

- 2 获取匹配的docID集合；以上步骤在生成Weight时，已经从索引文件中读取了倒排表（第【6】步），因此Weight的实例是知道哪些文档匹配这个Query，所以，第【23】步，通过weight实例获取匹配的docID集合

- 3 基于之前已经算出的【IDF值】，生成计算分数的【Similarity.SimScorer】对象，是的，这个对象就包含了各种公式的计算

- 4 收集结果；知道了满足查询条件的docID集合，又知道了算分的对象，很明显，就是要【收集】文档，然后为每一个文档【算分】了

- - 4.1 第【28】步，从匹配查询条件的docID集合中，取出一个

- - 4.2 第【30】步，收集这个docID

- - 4.3 第【31】步，收集的时候，给这个文档算分，这里就包含了你最关心的数学公式的使用

- - 4.4 第【33】步，放到队列；当前文档的分数，和已经在队列中的文档的分数对比，比最小的分数都小，就不进入队列，否则就放到队列中正确的位置

- - 4.5 以上[4.1],[4.2],[4.3],[4.4]是循环调用的，直到所有docID集合被收集

- 5 归并结果，分页返回；已经收集了docID,现在要做的就是分页返回结果了，第【34】步就是归并这些docID，然后返回topN doc

# diagram

![image](https://github.com/wuda0112/lucene-sequence-diagram/blob/master/sd-search.svg)
